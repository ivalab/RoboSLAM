<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Online Binary Feature Learning for Loop Closure</title>
<meta name="description" content="Research efforts related to closed-loop SLAM.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="https://ivalab.github.io/RoboSLAM/public/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://ivalab.github.io/RoboSLAM/public/css/font-awesome.min.css">
<link rel="stylesheet" href="https://ivalab.github.io/RoboSLAM/public/css/owl.carousel.css">
<link rel="stylesheet" href="https://ivalab.github.io/RoboSLAM/public/css/owl.theme.css">


  <link href="https://ivalab.github.io/RoboSLAM/public/css/style.ivalab.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="https://ivalab.github.io/RoboSLAM/public/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://ivalab.github.io/RoboSLAM/public/img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">

  <center style="margin-top:0px;margin-bottom:0px">
  <A HREF="https://ivalab.gatech.edu">
  <IMG SRC="https://ivalab.gatech.edu/ivalab.png">
  </A>
  </center>
    <a href="https://ivalab.github.io/RoboSLAM/public/">
    <h1 style="text-align:center;font-variant:small-caps" class="sidebar-heading">
    RoboSLAM Research
    </h1>
    </a>
    
      <p class="sidebar-p">Research efforts related to simultaneous localization and mapping algorithms for real-time, closed-loop operation of autonomous robots.</p>
    
    <ul class="sidebar-menu">
      
        <li><a href="https://ivalab.github.io/RoboSLAM/public/about/">About</a></li>
      
        <li><a href="https://ivalab.github.io/RoboSLAM/public/robots/">Robots</a></li>
      
        <li><a href="https://ivalab.github.io/RoboSLAM/public/research/">Research</a></li>
      
    </ul>

    <p class="social">
  
  
  
  
  
  
  
  
  <a href="https://github.com/ivalab" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
  <a href="https://github.com/ivaROS" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
  <a href="https://www.youtube.com/channel/UCKQ7FxpjoK-1l3Bp2qXCiYw/" data-animate-hover="pulse" class="external">
    <i class="fa fa-youtube"></i>
  </a>
  
  
</p>


  Select by Tags:<BR>
  
  <a href="https://ivalab.github.io/RoboSLAM/public/" style="padding:0px 5px 0px 5px">All</a>

    <div class="support" style="padding-top:15px">
      <p class="credit">
        
          Research supported in part by National Science Foundation.  Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. 
        
      </p>
      <p class="support">
        <p class="credit">
      
        
          
            <a target="_blank" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1816138&amp;HistoricalAwards=false">NSF &#35;1816138 </a><BR>
          
        
      
        
          
            AFRL
          
        
      
        </p>
      </p>
    </div>
    <div class="copyright">
      <p class="credit">
        
        Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>

</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="https://ivalab.github.io/RoboSLAM/public/">RoboSLAM Research</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Online Binary Feature Learning for Loop Closure</h1>
         <p><strong>Abstract:</strong>
Loop closure is an essential module in long-term SLAM, as detecting and recognizing
re-visited locations serves to bound localization drift and correct for
geometric map distortions. It also provides a mechanism to recover from
track loss. However, most methods employ offline learnt maps that cannot
be customized to the feature space of new environments. This work explores
a means to generate a loop closing map with online adaptive properties.</p>
<p>Loop closure is what I would call the <em>the lost robot problem</em> (in the vein
of the <em>kidnapped robot problem</em>).  No matter how much one wishes for
a SLAM system to succeed, there are times when it just might fail. Usually,
the local map process, if there is one, can prevent that by maintain a sense
of location by recognizing and exploiting high-frequency or low time interval
re-visits; imagine going to another room then back right away.  However, if the
re-visit spans a long enough distance or time, then more global data
re-association methods are needed; imagine going from home to
work/school/grandma's/etc.  Welcome to <em>loop closure</em>.</p>
<p>Loop closure is a tricky problem to solve. Make a mistake and it is over for your map;
unless you have a really good way of detecting mistakes during map re-optimization.
Miss a re-visit and you stay lost; that's certainly happened to me lots of times while driving!
Robots just don't have the corrective strategies humans have, so we roboticists have
to balance the trade-off between detection and error rate.  In our language, that's
called a precision-recall trade-off.
As someone whose background is control and dynamical systems,
we thought it would benefit the loop-closure process if there were a way to incorporate
motion insensitivity into the detection process (full credit goes to Guangcong for the initial idea during brainstorming sessions).
Mathematically, the ideal outcome would be to have motion invariance, but
theoeretically proving and then deriving an algorithm for this may or may not
provide dividends per my colleague Stefano Soatto's findings.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>
Sometimes the answer leads to an efficient algorithm, sometimes the
computational complexity is too high.  However, insensitivity is often much
easier to implement in practice and has nice computational or numerical
properties arising from the fact that insensitivity is like an <em>approximate
invariance</em> (my words).  In controls, we love insensitivity to nuisance
signals. That idea fundamentally motivates and describes our SLAM research.</p>
<p>Anyhow, back to the method at hand. One form of loop &hellip; MORE DETAILS TO COME &hellip;  <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>S. Soatto. &ldquo;Steps Towards a Theory of Visual Information: Active PErception, Signal-to-Symbol Conversion and the Interplay Between Sensing and Control.&rdquo; 2011-2017. <a href="https://arxiv.org/abs/1110.2053">arXiv</a>. He keeps changing the title and the document. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>S. Soatto and A. Chiuso. &ldquo;Visual Representations: Defining Properties and Deep Approximations.&rdquo; 2014-2016. <a href="https://arxiv.org/abs/1411.7676">arXiv</a>. Also a living manuscript. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>G. Zhang, M.J. Lilly, and P.A. Vela. &ldquo;Learning Binary Features Online from Motion Dynamics for Incremental Loop-Closure Detection and Place Recognition.&rdquo; <em>ICRA</em>, pp. 765-772, 2016.  <a href="https://ieeexplore.ieee.org/document/7487205">Abstract</a>. IEEE <a href="https://ieeexplore.ieee.org/document/7487205">pdf</a>. <a href="https://arxiv.org/abs/1601.03821">arXiv</a>. <em>Best Robotic Vision Paper Award Finalist</em>. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://ivalab.github.io/RoboSLAM/public/js/jquery.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/bootstrap.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/jquery.cookie.js"> </script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/ekko-lightbox.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/jquery.scrollTo.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/masonry.pkgd.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/imagesloaded.pkgd.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/owl.carousel.min.js"></script>
<script src="https://ivalab.github.io/RoboSLAM/public/js/front.js"></script>



</body>
</html>
